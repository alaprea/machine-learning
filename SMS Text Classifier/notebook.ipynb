{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>ham</td>\n",
       "      <td>just woke up. yeesh its late. but i didn't fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>ham</td>\n",
       "      <td>what do u reckon as need 2 arrange transport i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry into our £250 weekly competition ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>spam</td>\n",
       "      <td>-pls stop bootydelious (32/f) is inviting you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>ham</td>\n",
       "      <td>tell my  bad character which u dnt lik in me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "0      ham  ahhhh...just woken up!had a bad dream about u ...\n",
       "1      ham                           you can never do nothing\n",
       "2      ham  now u sound like manky scouse boy steve,like! ...\n",
       "3      ham  mum say we wan to go then go... then she can s...\n",
       "4      ham  never y lei... i v lazy... got wat? dat day ü ...\n",
       "...    ...                                                ...\n",
       "4174   ham  just woke up. yeesh its late. but i didn't fal...\n",
       "4175   ham  what do u reckon as need 2 arrange transport i...\n",
       "4176  spam  free entry into our £250 weekly competition ju...\n",
       "4177  spam  -pls stop bootydelious (32/f) is inviting you ...\n",
       "4178   ham  tell my  bad character which u dnt lik in me. ...\n",
       "\n",
       "[4179 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we read both tsv and convert them into a valid dataframe\n",
    "train_df = pd.read_csv('train-data.tsv', sep='\\t', header=None)\n",
    "train_df.columns = ['spam', 'text']\n",
    "\n",
    "valid_df = pd.read_csv('valid-data.tsv', sep='\\t', header=None)\n",
    "valid_df.columns = ['spam', 'text']\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>just woke up. yeesh its late. but i didn't fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>what do u reckon as need 2 arrange transport i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry into our £250 weekly competition ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1</td>\n",
       "      <td>-pls stop bootydelious (32/f) is inviting you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>0</td>\n",
       "      <td>tell my  bad character which u dnt lik in me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                               text\n",
       "0        0  ahhhh...just woken up!had a bad dream about u ...\n",
       "1        0                           you can never do nothing\n",
       "2        0  now u sound like manky scouse boy steve,like! ...\n",
       "3        0  mum say we wan to go then go... then she can s...\n",
       "4        0  never y lei... i v lazy... got wat? dat day ü ...\n",
       "...    ...                                                ...\n",
       "4174     0  just woke up. yeesh its late. but i didn't fal...\n",
       "4175     0  what do u reckon as need 2 arrange transport i...\n",
       "4176     1  free entry into our £250 weekly competition ju...\n",
       "4177     1  -pls stop bootydelious (32/f) is inviting you ...\n",
       "4178     0  tell my  bad character which u dnt lik in me. ...\n",
       "\n",
       "[4179 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We convert the kind column into a one-hot\n",
    "train_df['spam'] = train_df['spam'].map({'ham': 0,'spam': 1})\n",
    "valid_df['spam'] = valid_df['spam'].map({'ham': 0,'spam': 1})\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 8995\n"
     ]
    }
   ],
   "source": [
    "# We combine both df to tokenize the words \n",
    "combined_df = pd.concat([train_df, valid_df])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(combined_df['text'])\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid_df['text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index)\n",
    "print(\"Number of unique words:\", vocab_size)\n",
    "\n",
    "# Padding sequences to ensure they have the same length\n",
    "max_sequence_length = 100\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "valid_sequences = pad_sequences(valid_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4174    0\n",
       "4175    0\n",
       "4176    1\n",
       "4177    1\n",
       "4178    0\n",
       "Name: spam, Length: 4179, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get the train and test labels\n",
    "train_labels = train_df.pop('spam')\n",
    "valid_labels = valid_df.pop('spam')\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 32)           287872    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 296225 (1.13 MB)\n",
      "Trainable params: 296225 (1.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We create the model by adding a Embedding layer that will make indices for our words, an lstm layer and finally a dense layer with one output with a sigmoid activation where 1 = spam and 0 = ham\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=vocab_size + 1, output_dim=32, input_length=max_sequence_length))\n",
    "model.add(tf.keras.layers.LSTM(32))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "# We compile the model\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 8.7032e-04 - accuracy: 0.9998 - val_loss: 0.0447 - val_accuracy: 0.9892\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 6.4213e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9892\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 4.9743e-04 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9907\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 3.9467e-04 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9907\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 3.2326e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9907\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 2.6661e-04 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9892\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 2.3583e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9907\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 2.0048e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9907\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 1.7410e-04 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9907\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 1.5219e-04 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9907\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 1.3435e-04 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9907\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 1.1950e-04 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9907\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 1.0560e-04 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9907\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 9.4506e-05 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9907\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 8.4743e-05 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9907\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 7.5755e-05 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9907\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 6.8623e-05 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9914\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 3s 24ms/step - loss: 6.2112e-05 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9914\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 3s 25ms/step - loss: 5.6472e-05 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9914\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 3s 26ms/step - loss: 5.1272e-05 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "# Finally, we train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_sequences, train_labels, epochs=20, validation_data=(valid_sequences,valid_labels), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "# function to predict messages based on model\n",
    "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text):\n",
    "  prediction = ''\n",
    "  input_text = [pred_text]\n",
    "  input_sequences = tokenizer.texts_to_sequences(input_text)\n",
    "  input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "  predictions = model.predict(input_sequences)\n",
    "  rounded_predictions = np.round(predictions)\n",
    "\n",
    "  if rounded_predictions == 1.0:\n",
    "     prediction = 'spam'\n",
    "  else:\n",
    "    prediction = 'ham'\n",
    "  return prediction\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    if prediction != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
